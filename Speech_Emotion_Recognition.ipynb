{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaryan/ML-Project/blob/main/Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ_0B6JAtZzq"
      },
      "source": [
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "\n",
        "## Package\n",
        "import glob\n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "py.init_notebook_mode(connected=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsCpoCThtq8B"
      },
      "source": [
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFHVCwBAtsqa"
      },
      "source": [
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT7DVkNmtwBq"
      },
      "source": [
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoA4Tx9mtx98"
      },
      "source": [
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive/')\n",
        "  %cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtoSsyc-tzTV"
      },
      "source": [
        "# Data Directory\n",
        "\n",
        "dir_list = os.listdir(r\"/gdrive/My Drive/final test data\")\n",
        "dir_list.sort()\n",
        "print (dir_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsmuAWwZykoW"
      },
      "source": [
        "for file in dir_list:\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQ0dL0O2TLJ"
      },
      "source": [
        "# Create DataFrame for Data intel\n",
        "data_df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender',\n",
        "                                'intensity', 'statement', 'repetition', 'emotion'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKLSagxy2VS8"
      },
      "source": [
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU4GKCeS2YNc"
      },
      "source": [
        "# Create DataFrame for Data intel\n",
        "data_df = pd.DataFrame(columns=['path', 'source', 'actor', 'gender',\n",
        "                                'intensity', 'statement', 'repetition', 'emotion'])\n",
        "count = 0\n",
        "for i in dir_list:\n",
        "    file_list = os.listdir(r\"/gdrive/My Drive/final test data\"+ i)\n",
        "    for f in file_list:\n",
        "        nm = f.split('.')[0].split('-')\n",
        "        path = r\"/gdrive/My Drive/final test data\" + i + '/' + f\n",
        "        src = int(nm[1])\n",
        "        actor = int(nm[1])\n",
        "        emotion = int(nm[2])\n",
        "\n",
        "        if int(actor)%2 == 0:\n",
        "            gender = \"female\"\n",
        "        else:\n",
        "            gender = \"male\"\n",
        "\n",
        "        if nm[3] == '01':\n",
        "            intensity = 0\n",
        "        else:\n",
        "            intensity = 1\n",
        "\n",
        "        if nm[4] == '01':\n",
        "            statement = 0\n",
        "        else:\n",
        "            statement = 1\n",
        "\n",
        "        if nm[5] == '01':\n",
        "            repeat = 0\n",
        "        else:\n",
        "            repeat = 1\n",
        "\n",
        "        data_df.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp8kNpgN2Z_T"
      },
      "source": [
        "print (len(data_df))\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvBbJYLz3qKS"
      },
      "source": [
        "filename = data_df.path[1021]\n",
        "print (filename)\n",
        "\n",
        "samples, sample_rate = librosa.load(filename)\n",
        "sample_rate, samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCj3y61D3xus"
      },
      "source": [
        "len(samples), sample_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXqIpPLv3zZJ"
      },
      "source": [
        "def log_specgram(audio, sample_rate, window_size=20,\n",
        "                 step_size=10, eps=1e-10):\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "    freqs, times, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaJeask-31xE"
      },
      "source": [
        "sample_rate/ len(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9fECEQJ34ht"
      },
      "source": [
        "# Plotting Wave Form and Spectrogram\n",
        "freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.set_title('Raw wave of ' + filename)\n",
        "ax1.set_ylabel('Amplitude')\n",
        "librosa.display.waveplot(samples, sr=sample_rate)\n",
        "\n",
        "ax2 = fig.add_subplot(212)\n",
        "ax2.imshow(spectrogram.T, aspect='auto', origin='lower',\n",
        "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
        "ax2.set_yticks(freqs[::16])\n",
        "ax2.set_xticks(times[::16])\n",
        "ax2.set_title('Spectrogram of ' + filename)\n",
        "ax2.set_ylabel('Freqs in Hz')\n",
        "ax2.set_xlabel('Seconds')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCQbTiud35yf"
      },
      "source": [
        "mean = np.mean(spectrogram, axis=0)\n",
        "std = np.std(spectrogram, axis=0)\n",
        "spectrogram = (spectrogram - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjy8ClAN38Ni"
      },
      "source": [
        "# Trim the silence voice\n",
        "aa , bb = librosa.effects.trim(samples, top_db=30)\n",
        "aa, bb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkNdj3lK4myn"
      },
      "source": [
        "  # Plotting Mel Power Spectrogram\n",
        "S = librosa.feature.melspectrogram(aa, sr=sample_rate, n_mels=128)\n",
        "\n",
        "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
        "log_S = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n",
        "plt.title('Mel power spectrogram ')\n",
        "plt.colorbar(format='%+02.0f dB')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxEG8OC44pSx"
      },
      "source": [
        "# Plotting MFCC\n",
        "mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
        "\n",
        "# Let's pad on the first and second deltas while we're at it\n",
        "delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.specshow(delta2_mfcc)\n",
        "plt.ylabel('MFCC coeffs')\n",
        "plt.xlabel('Time')\n",
        "plt.title('MFCC')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEj11My41a8"
      },
      "source": [
        "import IPython.display as ipd\n",
        "# Original Sound\n",
        "ipd.Audio(samples, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i9Xvqr44-oV"
      },
      "source": [
        "# Silence trimmed Sound by librosa.effects.trim()\n",
        "ipd.Audio(aa, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGWOh6Fx5KZp"
      },
      "source": [
        "# Silence trimmed Sound by manuel trimming\n",
        "samples_cut = samples[10000:-12500]\n",
        "ipd.Audio(samples_cut, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v245z9d95jas"
      },
      "source": [
        "# 2 class: Positive & Negative\n",
        "\n",
        "# Positive: Calm, Happy\n",
        "# Negative: Angry, Fearful, Sad\n",
        "\n",
        "label2_list = []\n",
        "for i in range(len(data_df)):\n",
        "    if data_df.emotion[i] == 2: # Calm\n",
        "        lb = \"_positive\"\n",
        "    elif data_df.emotion[i] == 3: # Happy\n",
        "        lb = \"_positive\"\n",
        "    elif data_df.emotion[i] == 4: # Sad\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 5: # Angry\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 6: # Fearful\n",
        "        lb = \"_negative\"\n",
        "    else:\n",
        "        lb = \"_none\"\n",
        "\n",
        "    # Add gender to the label\n",
        "    label2_list.append(data_df.gender[i] + lb)\n",
        "\n",
        "len(label2_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdmfMC_05lWs"
      },
      "source": [
        "# 2 class: Positive & Negative\n",
        "\n",
        "# Positive: Calm, Happy\n",
        "# Negative: Angry, Fearful, Sad\n",
        "\n",
        "label2_list = []\n",
        "for i in range(len(data_df)):\n",
        "    if data_df.emotion[i] == 2: # Calm\n",
        "        lb = \"_positive\"\n",
        "    elif data_df.emotion[i] == 3: # Happy\n",
        "        lb = \"_positive\"\n",
        "    elif data_df.emotion[i] == 4: # Sad\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 5: # Angry\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 6: # Fearful\n",
        "        lb = \"_negative\"\n",
        "    else:\n",
        "        lb = \"_none\"\n",
        "\n",
        "    # Add gender to the label\n",
        "    label2_list.append(data_df.gender[i] + lb)\n",
        "\n",
        "len(label2_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZHuY8Uo5m7d"
      },
      "source": [
        "#3 class: Positive, Neutral & Negative\n",
        "\n",
        "# Positive:  Happy\n",
        "# Negative: Angry, Fearful, Sad\n",
        "# Neutral: Calm, Neutral\n",
        "\n",
        "label3_list = []\n",
        "for i in range(len(data_df)):\n",
        "    if data_df.emotion[i] == 1: # Neutral\n",
        "        lb = \"_neutral\"\n",
        "    elif data_df.emotion[i] == 2: # Calm\n",
        "        lb = \"_neutral\"\n",
        "    elif data_df.emotion[i] == 3: # Happy\n",
        "        lb = \"_positive\"\n",
        "    elif data_df.emotion[i] == 4: # Sad\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 5: # Angry\n",
        "        lb = \"_negative\"\n",
        "    elif data_df.emotion[i] == 6: # Fearful\n",
        "        lb = \"_negative\"\n",
        "    else:\n",
        "        lb = \"_none\"\n",
        "\n",
        "    # Add gender to the label\n",
        "    label3_list.append(data_df.gender[i] + lb)\n",
        "\n",
        "len(label3_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUiJzrX6fU1"
      },
      "source": [
        "# 5 class: angry, calm, sad, happy & fearful\n",
        "label5_list = []\n",
        "for i in range(len(data_df)):\n",
        "    if data_df.emotion[i] == 2:\n",
        "        lb = \"_calm\"\n",
        "    elif data_df.emotion[i] == 3:\n",
        "        lb = \"_happy\"\n",
        "    elif data_df.emotion[i] == 4:\n",
        "        lb = \"_sad\"\n",
        "    elif data_df.emotion[i] == 5:\n",
        "        lb = \"_angry\"\n",
        "    elif data_df.emotion[i] == 6:\n",
        "        lb = \"_fearful\"\n",
        "    else:\n",
        "        lb = \"_none\"\n",
        "\n",
        "    # Add gender to the label\n",
        "    label5_list.append(data_df.gender[i] + lb)\n",
        "\n",
        "len(label5_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEwBz2jm6yaP"
      },
      "source": [
        "# All class\n",
        "\n",
        "label8_list = []\n",
        "for i in range(len(data_df)):\n",
        "    if data_df.emotion[i] == 1:\n",
        "        lb = \"_neutral\"\n",
        "    elif data_df.emotion[i] == 2:\n",
        "        lb = \"_calm\"\n",
        "    elif data_df.emotion[i] == 3:\n",
        "        lb = \"_happy\"\n",
        "    elif data_df.emotion[i] == 4:\n",
        "        lb = \"_sad\"\n",
        "    elif data_df.emotion[i] == 5:\n",
        "        lb = \"_angry\"\n",
        "    elif data_df.emotion[i] == 6:\n",
        "        lb = \"_fearful\"\n",
        "    elif data_df.emotion[i] == 7:\n",
        "        lb = \"_disgust\"\n",
        "    elif data_df.emotion[i] == 8:\n",
        "        lb = \"_surprised\"\n",
        "    else:\n",
        "        lb = \"_none\"\n",
        "\n",
        "    # Add gender to the label\n",
        "    label8_list.append(data_df.gender[i]  + lb)\n",
        "\n",
        "len(label8_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqb-CC7360Dx"
      },
      "source": [
        "# Select the label set you want by commenting the unwanteds.\n",
        "\n",
        "data_df['label'] = label2_list\n",
        "#data_df['label'] = label3_list\n",
        "#data_df['label'] = label5_list\n",
        "#data_df['label'] = label8_list\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlGaq8IM64qh"
      },
      "source": [
        "# Plotting the emotion distribution\n",
        "\n",
        "def plot_emotion_dist(dist, color_code='#C2185B', title=\"Plot\"):\n",
        "    \"\"\"\n",
        "    To plot the data distributioin by class.\n",
        "    Arg:\n",
        "      dist: pandas series of label count.\n",
        "    \"\"\"\n",
        "    tmp_df = pd.DataFrame()\n",
        "    tmp_df['Emotion'] = list(dist.keys())\n",
        "    tmp_df['Count'] = list(dist)\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    ax = sns.barplot(x=\"Emotion\", y='Count', color=color_code, data=tmp_df)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(),rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxxeHQVg66qn"
      },
      "source": [
        "a = data_df.label.value_counts()\n",
        "plot_emotion_dist(a, \"#2962FF\", \"Emotion Distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoX6AUfH67-a"
      },
      "source": [
        "# Female Data Set\n",
        "\n",
        "## Uncomment all below to use Female set\n",
        "\n",
        "# data2_df = data_df.copy()\n",
        "# data2_df = data2_df[data2_df.label != \"male_none\"]\n",
        "# data2_df = data2_df[data2_df.label != \"female_none\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_happy\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_angry\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_sad\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_fearful\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_calm\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_positive\"]\n",
        "# data2_df = data2_df[data2_df.label != \"male_negative\"].reset_index(drop=True)\n",
        "\n",
        "# tmp1 = data2_df[data2_df.actor == 22]\n",
        "# tmp2 = data2_df[data2_df.actor == 24]\n",
        "# data3_df = pd.concat([tmp1, tmp2],ignore_index=True).reset_index(drop=True)\n",
        "# data2_df = data2_df[data2_df.actor != 22]\n",
        "# data2_df = data2_df[data2_df.actor != 24].reset_index(drop=True)\n",
        "# print (len(data2_df))\n",
        "# data2_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r43ra4A7AHo"
      },
      "source": [
        "# Male Data Set\n",
        "\n",
        "## Uncomment all below to use Male set\n",
        "\n",
        "data2_df = data_df.copy()\n",
        "data2_df = data2_df[data2_df.label != \"male_none\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_none\"].reset_index(drop=True)\n",
        "data2_df = data2_df[data2_df.label != \"female_neutral\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_happy\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_angry\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_sad\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_fearful\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_calm\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_positive\"]\n",
        "data2_df = data2_df[data2_df.label != \"female_negative\"].reset_index(drop=True)\n",
        "\n",
        "tmp1 = data2_df[data2_df.actor == 21]\n",
        "tmp2 = data2_df[data2_df.actor == 22]\n",
        "tmp3 = data2_df[data2_df.actor == 23]\n",
        "tmp4 = data2_df[data2_df.actor == 24]\n",
        "data3_df = pd.concat([tmp1, tmp3],ignore_index=True).reset_index(drop=True)\n",
        "data2_df = data2_df[data2_df.actor != 21]\n",
        "data2_df = data2_df[data2_df.actor != 22]\n",
        "data2_df = data2_df[data2_df.actor != 23].reset_index(drop=True)\n",
        "data2_df = data2_df[data2_df.actor != 24].reset_index(drop=True)\n",
        "print (len(data2_df))\n",
        "data2_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRwbRdda7Biu"
      },
      "source": [
        "print (len(data3_df))\n",
        "data3_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSvnr917FVa"
      },
      "source": [
        "data = pd.DataFrame(columns=['feature'])\n",
        "for i in tqdm(range(len(data2_df))):\n",
        "    X, sample_rate = librosa.load(data2_df.path[i], res_type='kaiser_fast',duration=input_duration,sr=22050*2,offset=0.5)\n",
        "#     X = X[10000:90000]\n",
        "    sample_rate = np.array(sample_rate)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "    feature = mfccs\n",
        "    data.loc[i] = [feature]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIC8UFYj7Gt8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdOaRTYA8Bw2"
      },
      "source": [
        "df3 = pd.DataFrame(data['feature'].values.tolist())\n",
        "labels = data2_df.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_hNJipv8EF0"
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKY3oc48FJ0"
      },
      "source": [
        "newdf = pd.concat([df3,labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykeGDL8b8GbA"
      },
      "source": [
        "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})\n",
        "len(rnewdf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MsYH9vL8Hrm"
      },
      "source": [
        "rnewdf.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSx7S1-l8Kba"
      },
      "source": [
        "rnewdf.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2rOR1T98MOZ"
      },
      "source": [
        "rnewdf = rnewdf.fillna(0)\n",
        "rnewdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQlvHeRN8Nla"
      },
      "source": [
        "def plot_time_series(data):\n",
        "    \"\"\"\n",
        "    Plot the Audio Frequency.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(14, 8))\n",
        "    plt.title('Raw wave ')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.plot(np.linspace(0, 1, len(data)), data)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def noise(data):\n",
        "    \"\"\"\n",
        "    Adding White Noise.\n",
        "    \"\"\"\n",
        "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
        "    noise_amp = 0.005*np.random.uniform()*np.amax(data)\n",
        "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def shift(data):\n",
        "    \"\"\"\n",
        "    Random Shifting.\n",
        "    \"\"\"\n",
        "    s_range = int(np.random.uniform(low=-5, high = 5)*500)\n",
        "    return np.roll(data, s_range)\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    \"\"\"\n",
        "    Streching the Sound.\n",
        "    \"\"\"\n",
        "    data = librosa.effects.time_stretch(data, rate)\n",
        "    return data\n",
        "\n",
        "def pitch(data, sample_rate):\n",
        "    \"\"\"\n",
        "    Pitch Tuning.\n",
        "    \"\"\"\n",
        "    bins_per_octave = 12\n",
        "    pitch_pm = 2\n",
        "    pitch_change =  pitch_pm * 2*(np.random.uniform())\n",
        "    data = librosa.effects.pitch_shift(data.astype('float64'),\n",
        "                                      sample_rate, n_steps=pitch_change,\n",
        "                                      bins_per_octave=bins_per_octave)\n",
        "    return data\n",
        "\n",
        "def dyn_change(data):\n",
        "    \"\"\"\n",
        "    Random Value Change.\n",
        "    \"\"\"\n",
        "    dyn_change = np.random.uniform(low=1.5,high=3)\n",
        "    return (data * dyn_change)\n",
        "\n",
        "def speedNpitch(data):\n",
        "    \"\"\"\n",
        "    peed and Pitch Tuning.\n",
        "    \"\"\"\n",
        "    # you can change low and high here\n",
        "    length_change = np.random.uniform(low=0.8, high = 1)\n",
        "    speed_fac = 1.0  / length_change\n",
        "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
        "    minlen = min(data.shape[0], tmp.shape[0])\n",
        "    data *= 0\n",
        "    data[0:minlen] = tmp[0:minlen]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGWT9TYQ8PEr"
      },
      "source": [
        "X, sample_rate = librosa.load(data2_df.path[216], res_type='kaiser_fast',duration=4,sr=22050*2,offset=0.5)\n",
        "plot_time_series(X)\n",
        "ipd.Audio(X, rate=sample_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maPTuwvL8QVS"
      },
      "source": [
        "x = pitch(X, sample_rate)\n",
        "plot_time_series(x)\n",
        "ipd.Audio(x, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpsqJKRp8UCY"
      },
      "source": [
        "# Augmentation Method 1\n",
        "\n",
        "syn_data1 = pd.DataFrame(columns=['feature', 'label'])\n",
        "for i in tqdm(range(len(data2_df))):\n",
        "    X, sample_rate = librosa.load(data2_df.path[i], res_type='kaiser_fast',duration=input_duration,sr=22050*2,offset=0.5)\n",
        "    if data2_df.label[i]:\n",
        "#     if data2_df.label[i] == \"male_positive\":\n",
        "        X = noise(X)\n",
        "        sample_rate = np.array(sample_rate)\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "        feature = mfccs\n",
        "        a = random.uniform(0, 1)\n",
        "        syn_data1.loc[i] = [feature, data2_df.label[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdmdNkda8Wau"
      },
      "source": [
        "syn_data2 = pd.DataFrame(columns=['feature', 'label'])\n",
        "for i in tqdm(range(len(data2_df))):\n",
        "    X, sample_rate = librosa.load(data2_df.path[i], res_type='kaiser_fast',duration=input_duration,sr=22050*2,offset=0.5)\n",
        "    if data2_df.label[i]:\n",
        "#     if data2_df.label[i] == \"male_positive\":\n",
        "        X = pitch(X, sample_rate)\n",
        "        sample_rate = np.array(sample_rate)\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "        feature = mfccs\n",
        "        a = random.uniform(0, 1)\n",
        "        syn_data2.loc[i] = [feature, data2_df.label[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU3gkMU_8XwO"
      },
      "source": [
        "len(syn_data1), len(syn_data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEwQgCo08Y18"
      },
      "source": [
        "syn_data1 = syn_data1.reset_index(drop=True)\n",
        "syn_data2 = syn_data2.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ypwLG-m8aCA"
      },
      "source": [
        "df4 = pd.DataFrame(syn_data1['feature'].values.tolist())\n",
        "labels4 = syn_data1.label\n",
        "syndf1 = pd.concat([df4,labels4], axis=1)\n",
        "syndf1 = syndf1.rename(index=str, columns={\"0\": \"label\"})\n",
        "syndf1 = syndf1.fillna(0)\n",
        "len(syndf1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr-W7tip8bQ9"
      },
      "source": [
        "syndf1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaO3xqeR8ciq"
      },
      "source": [
        "df4 = pd.DataFrame(syn_data2['feature'].values.tolist())\n",
        "labels4 = syn_data2.label\n",
        "syndf2 = pd.concat([df4,labels4], axis=1)\n",
        "syndf2 = syndf2.rename(index=str, columns={\"0\": \"label\"})\n",
        "syndf2 = syndf2.fillna(0)\n",
        "len(syndf2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WRAI8xY8fE-"
      },
      "source": [
        "syndf2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlPRuqCV8g6H"
      },
      "source": [
        "# Combining the Augmented data with original\n",
        "combined_df = pd.concat([rnewdf, syndf1, syndf2], ignore_index=True)\n",
        "combined_df = combined_df.fillna(0)\n",
        "combined_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEEy2TK68iTt"
      },
      "source": [
        "#  Stratified Shuffle Split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "X = combined_df.drop(['label'], axis=1)\n",
        "y = combined_df.label\n",
        "xxx = StratifiedShuffleSplit(1, test_size=0.2, random_state=12)\n",
        "for train_index, test_index in xxx.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIJOUfZb8joP"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Qwv8H88npO"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7bAk2o98o3u"
      },
      "source": [
        "X_train.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcPE-pau8qR-"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWFxDWDt8rjy"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_rh-b708szJ"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5qgRoSs8uBO"
      },
      "source": [
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAM99fTm8vNQ"
      },
      "source": [
        "# Set up Keras util functions\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    f_score = 2 * (p * r) / (p + r + K.epsilon())\n",
        "    return f_score\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX2VHHCl8wRw"
      },
      "source": [
        "# New model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(256, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "# Edit according to target class no.\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzVDGDb88xrj"
      },
      "source": [
        "# Original Model\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv1D(256, 5,padding='same', input_shape=(X_train.shape[1],1)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv1D(128, 5,padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "# model.add(MaxPooling1D(pool_size=(8)))\n",
        "# model.add(Conv1D(128, 5,padding='same',))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv1D(128, 5,padding='same',))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Conv1D(128, 5,padding='same',))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv1D(128, 5,padding='same',))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(5))\n",
        "# model.add(Activation('softmax'))\n",
        "# opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tQ9OB7o8zs_"
      },
      "source": [
        "# Plotting Model Summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgAtJO1C820b"
      },
      "source": [
        "# Compile your model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', fscore])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-T5SF4w83Nz"
      },
      "source": [
        "# Model Training\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700,\n",
        "                     validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWqVXZFP84kx"
      },
      "source": [
        "# Plotting the Train Valid Loss Graph\n",
        "\n",
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ndLSDDc86Jg"
      },
      "source": [
        "# Plotting the Train Valid Accuracy Graph\n",
        "\n",
        "plt.plot(cnnhistory.history['acc'])\n",
        "plt.plot(cnnhistory.history['val_acc'])\n",
        "plt.title('model acc')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8bYNEA87YI"
      },
      "source": [
        "len(data2_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWpqvBvk88yv"
      },
      "source": [
        "data_test = pd.DataFrame(columns=['feature'])\n",
        "for i in tqdm(range(len(data2_df))):\n",
        "    X, sample_rate = librosa.load(data2_df.path[i], res_type='kaiser_fast',duration=input_duration,sr=22050*2,offset=0.5)\n",
        "#     X = X[10000:90000]\n",
        "    sample_rate = np.array(sample_rate)\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
        "    feature = mfccs\n",
        "    data_test.loc[i] = [feature]\n",
        "\n",
        "test_valid = pd.DataFrame(data_test['feature'].values.tolist())\n",
        "test_valid = np.array(test_valid)\n",
        "test_valid_lb = np.array(data2_df.label)\n",
        "lb = LabelEncoder()\n",
        "test_valid_lb = np_utils.to_categorical(lb.fit_transform(test_valid_lb))\n",
        "test_valid = np.expand_dims(test_valid, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aZ_S44y893D"
      },
      "source": [
        "preds = model.predict(test_valid,\n",
        "                         batch_size=16,\n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEiBHAw58-5J"
      },
      "source": [
        "preds1=preds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNandmyS9CCB"
      },
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf4dYEaG9Clm"
      },
      "source": [
        "predictions = (lb.inverse_transform((abc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMFIwnLu9Dq1"
      },
      "source": [
        "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
        "preddf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba_4mGdD9F-F"
      },
      "source": [
        "actual=test_valid_lb.argmax(axis=1)\n",
        "abc123 = actual.astype(int).flatten()\n",
        "actualvalues = (lb.inverse_transform((abc123)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWhMUE_U9HmR"
      },
      "source": [
        "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
        "actualdf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPqRmgIi9KBv"
      },
      "source": [
        "finaldf = actualdf.join(preddf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFLJ4P3B9L1z"
      },
      "source": [
        "finaldf[20:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtjaW2bL9Nkx"
      },
      "source": [
        "finaldf.groupby('actualvalues').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkKjKW519QK0"
      },
      "source": [
        "finaldf.groupby('predictedvalues').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-gCmen29R3R"
      },
      "source": [
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    confusion_matrix: numpy.ndarray\n",
        "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix.\n",
        "        Similarly constructed ndarrays can also be used.\n",
        "    class_names: list\n",
        "        An ordered list of class names, in the order they index the given confusion matrix.\n",
        "    figsize: tuple\n",
        "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "        the second determining the vertical size. Defaults to (10,7).\n",
        "    fontsize: int\n",
        "        Font size for axes labels. Defaults to 14.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The resulting confusion matrix figure\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwvrqP_o9VAn"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_true = finaldf.actualvalues\n",
        "y_pred = finaldf.predictedvalues\n",
        "accuracy_score(y_true, y_pred)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJABUb3I-gkn"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_true, y_pred, average='macro') *100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlW8OLKJ-h0H"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(y_true, y_pred)\n",
        "c\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fna_D4Qz-jLE"
      },
      "source": [
        "# Visualize Confusion Matrix\n",
        "\n",
        "# class_names = ['male_angry', 'male_calm', 'male_fearful', 'male_happy', 'male_sad']\n",
        "# class_names = ['female_angry', 'female_calm', 'female_fearful', 'female_happy', 'female_sad']\n",
        "# class_names = ['male_negative', 'male_neutral', 'male_positive']\n",
        "class_names = ['male_negative', 'male_positive']\n",
        "# class_names = ['female_angry', 'female_calm', 'female_fearful', 'female_happy', 'female_sad', 'male_angry', 'male_calm', 'male_fearful', 'male_happy', 'male_sad']\n",
        "\n",
        "\n",
        "print_confusion_matrix(c, class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}